{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eb0af6d3",
      "metadata": {
        "id": "eb0af6d3"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def LemNormalize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghapus tanda baca\n",
        "    return text.split()  # Tokenisasi berdasarkan spasi\n"
      ],
      "metadata": {
        "id": "PSfdyQoW7tEp"
      },
      "id": "PSfdyQoW7tEp",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Unduh resource NLTK\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Membaca file CSV secara langsung\n",
        "data = pd.read_csv('curhatdong_100.csv', encoding='utf-8')\n",
        "\n",
        "# Preprocessing\n",
        "lemmer = WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([remove_punct_dict.get(c, c) for c in text])  # Menghapus tanda baca\n",
        "    return text.split()  # Tokenisasi berdasarkan spasi\n",
        "\n",
        "# Membuat list pertanyaan dan jawaban\n",
        "curhat_pertanyaan = data['Pertanyaan'].tolist()\n",
        "curhat_jawaban = data['Jawaban'].tolist()\n",
        "\n",
        "# Keyword\n",
        "GREETING_INPUTS = (\"halo\", \"hi\", \"hai\", \"hello\", \"hei\")\n",
        "GREETING_RESPONSES = [\n",
        "    \"Halo! Cerita apa yang ingin kamu bagikan hari ini?\",\n",
        "    \"Hi! Aku di sini untuk mendengarkan.\",\n",
        "    \"Halo, apa yang sedang kamu rasakan?\",\n",
        "]\n",
        "\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)\n",
        "\n",
        "def build_vsm_responses(user_response):\n",
        "    \"\"\"Menggunakan Vector Space Model untuk mencari kecocokan.\"\"\"\n",
        "    robo_response = ''\n",
        "\n",
        "    # Menambahkan input pengguna ke daftar pertanyaan untuk diproses\n",
        "    curhat_pertanyaan.append(user_response)\n",
        "\n",
        "    # Membuat representasi vektor TF-IDF\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english', token_pattern=None)\n",
        "    tfidf_matrix = TfidfVec.fit_transform(curhat_pertanyaan)\n",
        "\n",
        "    # Menghitung kesamaan kosinus\n",
        "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix)\n",
        "    similarity_scores = cosine_similarities.flatten()\n",
        "    sorted_indices = similarity_scores.argsort()[::-1][1:]\n",
        "\n",
        "    # Mendapatkan hasil terbaik\n",
        "    if similarity_scores[sorted_indices[0]] == 0:\n",
        "        robo_response = \"Maaf, aku belum punya jawaban untuk itu. Coba ceritakan lebih banyak.\"\n",
        "    else:\n",
        "        best_match_index = sorted_indices[0]\n",
        "        robo_response = curhat_jawaban[best_match_index]\n",
        "\n",
        "    # Menghapus input pengguna dari list pertanyaan untuk menjaga konsistensi data\n",
        "    curhat_pertanyaan.pop()\n",
        "    return robo_response\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AZHuq0M-gyj",
        "outputId": "c16c408a-c701-447d-88df-42535833bab4"
      },
      "id": "9AZHuq0M-gyj",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Chat Loop\n",
        "print(\"Halo, Selamat Datang di CurhatDong! Silahkan kamu ingin bercerita apa hari ini?. Ketik 'selesai' untuk keluar.\")\n",
        "while True:\n",
        "    user_input = input(\"Anda: \").lower()\n",
        "    if user_input == 'selesai':\n",
        "        print(\"CurhatDong: Terima kasih!\")\n",
        "        break\n",
        "    elif greeting(user_input):\n",
        "        print(f\"CurhatDong: {greeting(user_input)}\")\n",
        "    else:\n",
        "        print(f\"CurhatDong: {build_vsm_responses(user_input)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGqM8p42-sgp",
        "outputId": "8db496ea-c024-4247-db90-e4a5eebe9660"
      },
      "id": "IGqM8p42-sgp",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Halo, Selamat Datang di CurhatDong! Silahkan kamu ingin bercerita apa hari ini?. Ketik 'selesai' untuk keluar.\n",
            "Anda: aku takut masa depan\n",
            "CurhatDong: Ketakutan itu wajar. Coba fokus ke langkah kecil yang bisa kamu lakukan hari ini.\n",
            "Anda: selesai\n",
            "CurhatDong: Terima kasih!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}